{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers langchain-community langchain torch faiss-cpu numpy pypdf einops --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 19 23:11:25 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   39C    P8              11W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/RAG\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='TS-03109-5\n",
      "Testspezifikation zur Technischen\n",
      "Richtlinie TR-03109-5\n",
      "Version 1.1.1\n",
      "Datum 11.06.2024' metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'author': 'Bundesamt f√ºr Sicherheit in der Informationstechnik', 'keywords': 'Testspezifikation, TR-03109-5', 'subject': '', 'title': 'TS-03109-5 - Testspezifikation zur Technischen Richtlinie TR-03109-5 - Version 1.1.1 - Datum 11.06.2024', 'source': '/teamspace/studios/this_studio/RAG/pdfs/TR-03109-5_Testspezifikation_german.pdf', 'total_pages': 132, 'page': 0, 'page_label': 'i'}\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"/teamspace/studios/this_studio/RAG/pdfs/TR-03109-5_Testspezifikation_german.pdf\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "\n",
    "print(docs_after_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_after_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 132 documents loaded, with average characters equal to 1948.\n",
      "After split, there were 629 documents (chunks), with average characters equal to 423 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42579/2586944620.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embeddings = HuggingFaceEmbeddings(\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"jinaai/jina-embeddings-v3\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':device,\n",
    "    \"trust_remote_code\": True}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [ 0.12109375 -0.01940918  0.05224609 ... -0.01586914  0.00228882\n",
      "  0.00653076]\n",
      "Size of the embedding:  (1024,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vector index: FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)\n",
    "vectorstore.save_local(\"Faiss_index_german\")\n",
    "\n",
    "# vectorstore=FAISS.load_local(\"Faiss_index\",huggingface_embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents retrieved: 4 \n",
      " ---First one:---\n",
      "\n",
      "‚Ä¢ REQ.FA.ImportSmgwTrustAnchor.40\n",
      "‚Ä¢ REQ.FAKAT.SmgwAssociation.40\n",
      "Relevante Implementation-Conformance-Statements (ICS)\n",
      "‚Ä¢ ICS.IOP.HKS.TLSPROXY.20\n",
      "Vorbedingungen\n",
      "Status Bedeutung\n",
      "ClsDeviceIsUnpaired Das CLS-Ger√§t hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zur√ºck-\n",
      "gesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\n",
      "Tabelle 4.62 Status\n",
      "Testfallparameter\n",
      "‚Ä¢ CurrentActiveEmt: Der derzeit ausgew√§hlte aktive Externe Marktteilnehmer.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What are the system log for (FAU_SAR)? \"\"\"  \n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'Total Documents retrieved: {len(relevant_documents)} \\n ---First one:---\\n')\n",
    "print(relevant_documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from tokens import HF_TOKEN\n",
    "login(token =HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading LLM: llama3.2- 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What are the system log for (FAU_SAR)?  The system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    device=0, # CUDA id and for cpu use -1\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 500}\n",
    ")\n",
    "\n",
    "llm.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo Wie ghets? Ich bin ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nIch bin ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben f√ºr das 2. Semester gestellt. Ich bin sehr m√ºde und habe keine Zeit, mich um meine Hausaufgaben zu k√ºmmern. Kannst'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hallo Wie ghets?\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "llm.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"I can't find the final answer\".\n",
    "2. If you find the answer, write the answer in a concise way.\n",
    "3. Question will be in either English or German Language. Answer in the same language as of question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    " template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42579/2156977366.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrievalQA(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the system log for (FAU_SAR)? ',\n",
       " 'result': 'Use the following pieces of context to answer the question at the end. Please follow the following rules:\\n1. If you don\\'t know the answer, don\\'t try to make up an answer. Just say \"I can\\'t find the final answer\".\\n2. If you find the answer, write the answer in a concise way.\\n3. Answer in the same language as of question. It will be in either English or German Language. \\n\\n‚Ä¢ REQ.FA.ImportSmgwTrustAnchor.40\\n‚Ä¢ REQ.FAKAT.SmgwAssociation.40\\nRelevante Implementation-Conformance-Statements (ICS)\\n‚Ä¢ ICS.IOP.HKS.TLSPROXY.20\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Ger√§t hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zur√ºck-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.62 Status\\nTestfallparameter\\n‚Ä¢ CurrentActiveEmt: Der derzeit ausgew√§hlte aktive Externe Marktteilnehmer.\\n\\n‚Ä¢ REQ.FA.ImportClsKeyPairAndCert.40\\n‚Ä¢ REQ.FA.ImportClsKeyPairAndCert.50\\n‚Ä¢ REQ.FAKAT.SmgwAssociation.60\\nRelevante Implementation-Conformance-Statements (ICS)\\n‚Ä¢ ICS.FA.ImportClsKeyPairAndCert.10\\n‚Ä¢ ICS.IOP.HKS.TLSPROXY.10\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Ger√§t hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zur√ºck-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.26 Status\\nTestfallparameter\\n\\nAbgedeckte Anforderungen\\n‚Ä¢ REQ.FA.FwInstallation.10\\n‚Ä¢ REQ.FA.FwInstallation.40\\n‚Ä¢ REQ.FAKAT.FwUpdate.10\\nRelevante Implementation-Conformance-Statements (ICS)\\n‚Ä¢ ICS.FA.FwInstallation.10\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Ger√§t hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zur√ºck-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.18 Status\\nTestfallparameter\\n‚Ä¢ CurrentActiveEmt: Der derzeit ausgew√§hlte aktive Externe Marktteilnehmer.\\n\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.194 Status\\nTestfallparameter\\nBundesamt f√ºr Sicherheit in der Informationstechnik 69\\n\\nQuestion: What are the system log for (FAU_SAR)? \\n\\nHelpful Answer:\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for ('}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievalQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't find the final answer.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query):\n",
    "    qa_chain = RetrievalQA.from_llm(\n",
    "        llm, retriever=vectorstore.as_retriever(), prompt=PROMPT,return_source_documents=False\n",
    "    )\n",
    "    out=qa_chain(query)[\"result\"]\n",
    "    out=out.split(\"Helpful Answer:\")[-1].strip()\n",
    "\n",
    "    return out\n",
    "\n",
    "query=\"\"\"What are the system log for (FAU_SAR)? \"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.1 TC.CLS.MGMT.MustDoFactoryResetClsAsClient\n",
      "Version: 1.0.0\n",
      "Zweck\n",
      "Der Testfall pr√ºft, ob der Pr√ºfgegenstand dazu in der Lage ist, einen Reset auf Werkseinstellungen durchzu-\n",
      "f√ºhren.\n"
     ]
    }
   ],
   "source": [
    "#German Query\n",
    "\n",
    "query=\"\"\"Was ist der Testfall, um die F√§higkeit des Objekts zur Durchf√ºhrung der Werkseinstellung zu √ºberpr√ºfen?\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MustDoFactoryResetClsAsClient Zweck\n",
      "Der Zweck des MustDoFactoryResetClsAsClient ist es, den Pr√ºfgegenstand in der Lage zu machen, einen Reset auf Werkseinstellungen durchzuf√ºhren.\n"
     ]
    }
   ],
   "source": [
    "# short ambigous query\n",
    "\n",
    "query=\"\"\"MustDoFactoryResetClsAsClient Zweck\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of the Factory reset in the test case is to reset the CLS-Ger√§t (CLS-Ger√§t) to its default settings, which are typically set by the manufacturer. This is usually done to ensure that the system is in a clean and secure state,\n"
     ]
    }
   ],
   "source": [
    "# English query\n",
    "\n",
    "query=\"\"\"give me the test case for Factory setting\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't find the final answer.\n"
     ]
    }
   ],
   "source": [
    "## Checking on False cases\n",
    "\n",
    "query=\"\"\"Hallo wie ghets \"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This PDF is about the ICS.IOP.HKS.TLSPROXY.20 and ICS.IOP.HKS.TLSPROXY.10 documents, which are related to the Bundesamt f√ºr Sicherheit in der Informationstechnik (BASIS) and the Bundesamt f√ºr Sicherheit in der Informationstechnik 27 (BASIS 27).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query=\"\"\"Explain in brief, What this pdf is about?\"\"\"  \n",
    "print(ask_question(query))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
