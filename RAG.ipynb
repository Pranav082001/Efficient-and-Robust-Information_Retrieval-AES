{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers langchain-community langchain torch faiss-cpu numpy pypdf einops --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 19 23:11:25 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   39C    P8              11W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/RAG\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='TS-03109-5\n",
      "Testspezifikation zur Technischen\n",
      "Richtlinie TR-03109-5\n",
      "Version 1.1.1\n",
      "Datum 11.06.2024' metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'author': 'Bundesamt für Sicherheit in der Informationstechnik', 'keywords': 'Testspezifikation, TR-03109-5', 'subject': '', 'title': 'TS-03109-5 - Testspezifikation zur Technischen Richtlinie TR-03109-5 - Version 1.1.1 - Datum 11.06.2024', 'source': '/teamspace/studios/this_studio/RAG/pdfs/TR-03109-5_Testspezifikation_german.pdf', 'total_pages': 132, 'page': 0, 'page_label': 'i'}\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"/teamspace/studios/this_studio/RAG/pdfs/TR-03109-5_Testspezifikation_german.pdf\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "\n",
    "print(docs_after_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_after_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 132 documents loaded, with average characters equal to 1948.\n",
      "After split, there were 629 documents (chunks), with average characters equal to 423 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42579/2586944620.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embeddings = HuggingFaceEmbeddings(\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"jinaai/jina-embeddings-v3\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':device,\n",
    "    \"trust_remote_code\": True}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [ 0.12109375 -0.01940918  0.05224609 ... -0.01586914  0.00228882\n",
      "  0.00653076]\n",
      "Size of the embedding:  (1024,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vector index: FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)\n",
    "vectorstore.save_local(\"Faiss_index_german\")\n",
    "\n",
    "# vectorstore=FAISS.load_local(\"Faiss_index\",huggingface_embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents retrieved: 4 \n",
      " ---First one:---\n",
      "\n",
      "• REQ.FA.ImportSmgwTrustAnchor.40\n",
      "• REQ.FAKAT.SmgwAssociation.40\n",
      "Relevante Implementation-Conformance-Statements (ICS)\n",
      "• ICS.IOP.HKS.TLSPROXY.20\n",
      "Vorbedingungen\n",
      "Status Bedeutung\n",
      "ClsDeviceIsUnpaired Das CLS-Gerät hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zurück-\n",
      "gesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\n",
      "Tabelle 4.62 Status\n",
      "Testfallparameter\n",
      "• CurrentActiveEmt: Der derzeit ausgewählte aktive Externe Marktteilnehmer.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What are the system log for (FAU_SAR)? \"\"\"  \n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'Total Documents retrieved: {len(relevant_documents)} \\n ---First one:---\\n')\n",
    "print(relevant_documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from tokens import HF_TOKEN\n",
    "login(token =HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading LLM: llama3.2- 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What are the system log for (FAU_SAR)?  The system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log.  The system log for (FAU_SAR) is not available in the system log.\\nThe system log for (FAU_SAR) is not available in the system log. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    device=0, # CUDA id and for cpu use -1\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0.1, \"max_new_tokens\": 500}\n",
    ")\n",
    "\n",
    "llm.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo Wie ghets? Ich bin ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nIch bin ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst du mir helfen?\\n\\nHallo! Ich bin auch ein Student und ich habe gerade meine Hausaufgaben für das 2. Semester gestellt. Ich bin sehr müde und habe keine Zeit, mich um meine Hausaufgaben zu kümmern. Kannst'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hallo Wie ghets?\"\"\"  # Sample question, change to other questions you are interested in.\n",
    "llm.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If you don't know the answer, don't try to make up an answer. Just say \"I can't find the final answer\".\n",
    "2. If you find the answer, write the answer in a concise way.\n",
    "3. Question will be in either English or German Language. Answer in the same language as of question.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    " template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42579/2156977366.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrievalQA(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the system log for (FAU_SAR)? ',\n",
       " 'result': 'Use the following pieces of context to answer the question at the end. Please follow the following rules:\\n1. If you don\\'t know the answer, don\\'t try to make up an answer. Just say \"I can\\'t find the final answer\".\\n2. If you find the answer, write the answer in a concise way.\\n3. Answer in the same language as of question. It will be in either English or German Language. \\n\\n• REQ.FA.ImportSmgwTrustAnchor.40\\n• REQ.FAKAT.SmgwAssociation.40\\nRelevante Implementation-Conformance-Statements (ICS)\\n• ICS.IOP.HKS.TLSPROXY.20\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Gerät hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zurück-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.62 Status\\nTestfallparameter\\n• CurrentActiveEmt: Der derzeit ausgewählte aktive Externe Marktteilnehmer.\\n\\n• REQ.FA.ImportClsKeyPairAndCert.40\\n• REQ.FA.ImportClsKeyPairAndCert.50\\n• REQ.FAKAT.SmgwAssociation.60\\nRelevante Implementation-Conformance-Statements (ICS)\\n• ICS.FA.ImportClsKeyPairAndCert.10\\n• ICS.IOP.HKS.TLSPROXY.10\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Gerät hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zurück-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.26 Status\\nTestfallparameter\\n\\nAbgedeckte Anforderungen\\n• REQ.FA.FwInstallation.10\\n• REQ.FA.FwInstallation.40\\n• REQ.FAKAT.FwUpdate.10\\nRelevante Implementation-Conformance-Statements (ICS)\\n• ICS.FA.FwInstallation.10\\nVorbedingungen\\nStatus Bedeutung\\nClsDeviceIsUnpaired Das CLS-Gerät hat noch nicht mit einem SMGW kommuniziert bzw. es wurde zurück-\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.18 Status\\nTestfallparameter\\n• CurrentActiveEmt: Der derzeit ausgewählte aktive Externe Marktteilnehmer.\\n\\ngesetzt und hat seitdem nicht wieder mit einem SMGW kommuniziert.\\nTabelle 4.194 Status\\nTestfallparameter\\nBundesamt für Sicherheit in der Informationstechnik 69\\n\\nQuestion: What are the system log for (FAU_SAR)? \\n\\nHelpful Answer:\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for (FAU_SAR) is located in the following directory:\\n```\\nC:\\\\Program Files\\\\SMGW\\\\bin\\\\logs\\n```\\nThe system log for ('}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievalQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't find the final answer.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query):\n",
    "    qa_chain = RetrievalQA.from_llm(\n",
    "        llm, retriever=vectorstore.as_retriever(), prompt=PROMPT,return_source_documents=False\n",
    "    )\n",
    "    out=qa_chain(query)[\"result\"]\n",
    "    out=out.split(\"Helpful Answer:\")[-1].strip()\n",
    "\n",
    "    return out\n",
    "\n",
    "query=\"\"\"What are the system log for (FAU_SAR)? \"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.1 TC.CLS.MGMT.MustDoFactoryResetClsAsClient\n",
      "Version: 1.0.0\n",
      "Zweck\n",
      "Der Testfall prüft, ob der Prüfgegenstand dazu in der Lage ist, einen Reset auf Werkseinstellungen durchzu-\n",
      "führen.\n"
     ]
    }
   ],
   "source": [
    "#German Query\n",
    "\n",
    "query=\"\"\"Was ist der Testfall, um die Fähigkeit des Objekts zur Durchführung der Werkseinstellung zu überprüfen?\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MustDoFactoryResetClsAsClient Zweck\n",
      "Der Zweck des MustDoFactoryResetClsAsClient ist es, den Prüfgegenstand in der Lage zu machen, einen Reset auf Werkseinstellungen durchzuführen.\n"
     ]
    }
   ],
   "source": [
    "# short ambigous query\n",
    "\n",
    "query=\"\"\"MustDoFactoryResetClsAsClient Zweck\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of the Factory reset in the test case is to reset the CLS-Gerät (CLS-Gerät) to its default settings, which are typically set by the manufacturer. This is usually done to ensure that the system is in a clean and secure state,\n"
     ]
    }
   ],
   "source": [
    "# English query\n",
    "\n",
    "query=\"\"\"give me the test case for Factory setting\"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't find the final answer.\n"
     ]
    }
   ],
   "source": [
    "## Checking on False cases\n",
    "\n",
    "query=\"\"\"Hallo wie ghets \"\"\"  \n",
    "print(ask_question(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This PDF is about the ICS.IOP.HKS.TLSPROXY.20 and ICS.IOP.HKS.TLSPROXY.10 documents, which are related to the Bundesamt für Sicherheit in der Informationstechnik (BASIS) and the Bundesamt für Sicherheit in der Informationstechnik 27 (BASIS 27).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query=\"\"\"Explain in brief, What this pdf is about?\"\"\"  \n",
    "print(ask_question(query))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
